<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chat con Gemini 2.0 Flash</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600&display=swap" rel="stylesheet">

    <style>
        /* Basic Reset */
        * { margin: 0; padding: 0; box-sizing: border-box; }

        body {
            font-family: 'Inter', sans-serif; /* Use Inter font */
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 100vh;
            background-color: var(--bg-color, #f0f2f5);
            color: var(--text-color, #333);
            transition: background-color 0.3s, color 0.3s;
            padding: 1rem; /* Add padding for smaller screens */
        }

        /* Theme Variables */
        body[data-theme="light"] {
            --bg-color: #f0f2f5;
            --text-color: #333;
            --header-bg: #ffffff;
            --chat-bg: #ffffff;
            --input-bg: #ffffff;
            --user-msg-bg: #dcf8c6;
            --bot-msg-bg: #e9e9eb;
            --button-bg: #007bff;
            --button-text: #ffffff;
            --button-hover-bg: #0056b3;
            --icon-color: #555;
            --border-color: #ddd;
            --indicator-color: #ccc;
            --config-bg: #ffffff;
            --config-border: #e0e0e0;
            --shadow-color: rgba(0, 0, 0, 0.1);
            --stop-listen-bg: #6c757d;
            --stop-listen-hover-bg: #5a6268;
        }

        body[data-theme="dark"] {
            --bg-color: #121212;
            --text-color: #e0e0e0;
            --header-bg: #1e1e1e;
            --chat-bg: #1e1e1e;
            --input-bg: #2c2c2c;
            --user-msg-bg: #056162;
            --bot-msg-bg: #3a3a3a;
            --button-bg: #007bff; /* Keep button color consistent or adjust */
            --button-text: #ffffff;
            --button-hover-bg: #0056b3;
            --icon-color: #bbb;
            --border-color: #444;
            --indicator-color: #555;
            --config-bg: #2c2c2c;
            --config-border: #444;
            --shadow-color: rgba(255, 255, 255, 0.1);
            --stop-listen-bg: #6c757d;
            --stop-listen-hover-bg: #5a6268;
        }

        .app-container {
            background-color: var(--header-bg);
            border-radius: 12px; /* Rounded corners */
            box-shadow: 0 4px 15px var(--shadow-color);
            overflow: hidden;
            display: flex;
            flex-direction: column;
            width: 100%;
            max-width: 700px; /* Limit max width */
            height: 90vh; /* Limit height */
            max-height: 800px;
            position: relative; /* Needed for config menu positioning */
        }

        header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 1rem 1.5rem;
            border-bottom: 1px solid var(--border-color);
            background-color: var(--header-bg); /* Ensure header has bg */
        }

        header h1 {
            font-size: 1.25rem;
            font-weight: 600;
            display: flex;
            align-items: center;
            gap: 0.5rem;
            color: var(--text-color);
        }

        header h1 i {
            color: var(--button-bg);
        }

        .header-controls {
            display: flex;
            align-items: center;
            gap: 1rem;
        }

        /* Context Indicator */
        .context-indicator {
            font-size: 0.8rem;
            padding: 0.3rem 0.6rem;
            border-radius: 15px; /* Pill shape */
            background-color: var(--indicator-color);
            color: var(--bg-color); /* Contrast text */
            transition: background-color 0.3s;
            cursor: default; /* Indicate it's not clickable */
        }
        .context-indicator.empty { background-color: #dc3545; } /* Red for empty */
        .context-indicator.medium { background-color: #ffc107; } /* Yellow for medium */
        .context-indicator.full { background-color: #28a745; } /* Green for full */


        main {
            flex-grow: 1;
            display: flex;
            flex-direction: column;
            padding: 0 1.5rem 1rem; /* Add padding */
            overflow: hidden; /* Prevent content overflow */
            position: relative; /* Para posicionar elementos absolutos si fuera necesario */
        }

        #chat-container {
            flex-grow: 1;
            overflow-y: auto; /* Enable scrolling */
            padding: 1rem 0;
            margin-bottom: 1rem; /* Space before input */
            display: flex; /* To position typing indicator */
            flex-direction: column;
            scrollbar-width: thin; /* Firefox */
            scrollbar-color: var(--button-bg) var(--chat-bg); /* Firefox */
        }

        /* Webkit Scrollbar Styles */
        #chat-container::-webkit-scrollbar {
            width: 8px;
        }
        #chat-container::-webkit-scrollbar-track {
            background: var(--chat-bg);
            border-radius: 4px;
        }
        #chat-container::-webkit-scrollbar-thumb {
            background-color: var(--button-bg);
            border-radius: 4px;
            border: 2px solid var(--chat-bg);
        }

        #chat {
            display: flex;
            flex-direction: column;
            gap: 0.75rem; /* Space between messages */
        }

        .message {
            padding: 0.75rem 1rem;
            border-radius: 12px; /* Rounded messages */
            max-width: 80%;
            word-wrap: break-word;
            line-height: 1.4;
            position: relative; /* Para posicionar el botón de altavoz */
        }

        .user-message {
            background-color: var(--user-msg-bg);
            color: var(--text-color); /* Adjust if needed for contrast */
            align-self: flex-end;
            border-bottom-right-radius: 4px; /* Tail effect */
        }

        .bot-message {
            background-color: var(--bot-msg-bg);
            color: var(--text-color);
            align-self: flex-start;
            border-bottom-left-radius: 4px; /* Tail effect */
            padding-bottom: 2.2rem; /* Más espacio para el botón de altavoz */
        }

        /* Botón de altavoz para mensajes del bot */
        .speak-button {
            position: absolute;
            bottom: 8px; /* Ajustado */
            right: 10px;
            background: none;
            border: none;
            color: var(--button-bg);
            font-size: 1rem;
            cursor: pointer;
            opacity: 0.7;
            transition: opacity 0.2s;
            padding: 3px; /* Pequeño padding */
        }

        .speak-button:hover {
            opacity: 1;
        }

        .system-message {
            font-style: italic;
            color: var(--icon-color);
            align-self: center;
            font-size: 0.85rem;
            background-color: transparent;
            text-align: center;
            margin: 0.5rem 0;
        }

        /* Typing Indicator */
        #typing-indicator {
            display: flex;
            align-items: center;
            padding: 0.5rem 1rem;
            margin-top: 0.5rem; /* Space from last message */
            align-self: flex-start; /* Align with bot messages */
        }
        #typing-indicator.hidden { display: none; }
        .dot {
            width: 8px;
            height: 8px;
            margin: 0 3px;
            background-color: var(--icon-color);
            border-radius: 50%;
            animation: typing 1.4s infinite ease-in-out both;
        }
        .dot:nth-child(1) { animation-delay: -0.32s; }
        .dot:nth-child(2) { animation-delay: -0.16s; }
        @keyframes typing {
            0%, 80%, 100% { transform: scale(0); }
            40% { transform: scale(1.0); }
        }


        .input-area {
            display: flex;
            gap: 0.5rem;
            padding: 0.5rem;
            border: 1px solid var(--border-color);
            border-radius: 25px; /* Pill shape input area */
            background-color: var(--input-bg);
            margin-top: auto; /* Push input area to bottom within main */
        }

        #input {
            flex-grow: 1;
            border: none;
            outline: none;
            padding: 0.75rem 1rem;
            font-size: 1rem;
            background-color: transparent;
            color: var(--text-color);
        }
         #input::placeholder {
            color: var(--icon-color);
         }

        .icon-button {
            background: none;
            border: none;
            color: var(--button-bg);
            font-size: 1.25rem;
            cursor: pointer;
            padding: 0.5rem;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            transition: background-color 0.2s;
        }
        .icon-button:hover {
            background-color: rgba(0, 123, 255, 0.1); /* Subtle hover */
        }
        .icon-button i {
            display: block; /* Prevents small layout shifts */
        }


        .controls {
            display: flex;
            justify-content: center;
            gap: 0.75rem;
            margin-top: 1rem;
            flex-wrap: wrap; /* Allow buttons to wrap on small screens */
        }

        .control-button {
            background-color: var(--button-bg);
            color: var(--button-text);
            border: none;
            padding: 0.75rem 1.25rem;
            border-radius: 20px; /* Rounded buttons */
            cursor: pointer;
            font-size: 0.9rem;
            font-weight: 500;
            display: flex;
            align-items: center;
            gap: 0.5rem;
            transition: background-color 0.2s, box-shadow 0.2s;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
        }
        .control-button:hover:not(:disabled) {
            background-color: var(--button-hover-bg);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.15);
        }
        .control-button:disabled {
            background-color: var(--indicator-color);
            cursor: not-allowed;
            box-shadow: none;
        }
        .control-button i {
            font-size: 1rem;
        }
        /* Style for the explicit stop listening button */
        #explicitStopBtn {
            background-color: var(--stop-listen-bg);
        }
        #explicitStopBtn:hover:not(:disabled) {
            background-color: var(--stop-listen-hover-bg);
        }


        /* Config Menu */
        #configMenu {
            position: absolute;
            top: 0;
            right: 0;
            width: 300px;
            height: 100%;
            background-color: var(--config-bg);
            border-left: 1px solid var(--config-border);
            box-shadow: -5px 0 15px var(--shadow-color);
            transform: translateX(100%);
            transition: transform 0.3s ease-in-out;
            z-index: 10;
            display: flex;
            flex-direction: column;
            padding: 1.5rem;
            overflow-y: auto; /* Scroll if content overflows */
            visibility: hidden; /* Start hidden */
        }
        #configMenu:not(.hidden) {
            transform: translateX(0);
            visibility: visible; /* Make visible when not hidden */
        }
        #configMenu.hidden {
             transform: translateX(100%); /* Ensure it's hidden */
             visibility: hidden; /* Improve accessibility */
        }

        .config-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 1.5rem;
            padding-bottom: 1rem;
            border-bottom: 1px solid var(--border-color);
        }
        .config-header h3 {
            font-size: 1.1rem;
            font-weight: 600;
            color: var(--text-color);
        }
        .config-header .icon-button {
            color: var(--icon-color); /* Use subtle color */
        }

        .config-section {
            margin-bottom: 1.5rem;
        }
        .config-section h4 {
            font-size: 0.9rem;
            font-weight: 600;
            color: var(--text-color);
            margin-bottom: 0.75rem;
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }
        .config-section label {
            display: block;
            margin-bottom: 0.5rem;
            font-size: 0.9rem;
            color: var(--text-color);
        }
        .config-section select,
        .config-section input[type="range"] {
            width: 100%;
            padding: 0.5rem;
            border-radius: 6px;
            border: 1px solid var(--border-color);
            background-color: var(--input-bg);
            color: var(--text-color);
            font-size: 0.9rem;
        }
        .config-section input[type="range"] {
            cursor: pointer;
            padding: 0; /* Remove padding for range */
        }

        .slider-container {
            display: flex;
            align-items: center;
            gap: 0.75rem;
            margin-bottom: 0.25rem;
        }
        .slider-container i {
            color: var(--icon-color);
        }
        .config-section span[id$="Value"] { /* Select rateValue and pitchValue */
            display: block;
            text-align: center;
            font-size: 0.85rem;
            color: var(--icon-color);
            margin-top: 0.25rem;
        }

        .full-width-btn {
            width: 100%;
            background-color: #dc3545; /* Red for destructive action */
            color: white;
            border: none;
            padding: 0.75rem 1rem;
            border-radius: 6px;
            cursor: pointer;
            font-size: 0.9rem;
            font-weight: 500;
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 0.5rem;
            transition: background-color 0.2s;
        }
        .full-width-btn:hover {
            background-color: #c82333;
        }
        .full-width-btn i {
            font-size: 1rem;
        }
        .help-text {
            font-size: 0.8rem;
            color: var(--icon-color);
            margin-top: 0.5rem;
            text-align: center;
        }

        /* Theme Toggle Switch */
        .theme-toggle {
            display: flex;
            align-items: center;
            justify-content: space-between;
            gap: 0.5rem;
            font-size: 0.9rem;
        }
        .switch {
            position: relative;
            display: inline-block;
            width: 50px; /* Adjusted width */
            height: 28px; /* Adjusted height */
        }
        .switch input {
            opacity: 0;
            width: 0;
            height: 0;
        }
        .slider {
            position: absolute;
            cursor: pointer;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: #ccc;
            transition: .4s;
            border-radius: 28px; /* Fully rounded */
        }
        .slider:before {
            position: absolute;
            content: "";
            height: 20px; /* Adjusted size */
            width: 20px; /* Adjusted size */
            left: 4px; /* Adjusted position */
            bottom: 4px; /* Adjusted position */
            background-color: white;
            transition: .4s;
            border-radius: 50%;
        }
        input:checked + .slider {
            background-color: var(--button-bg);
        }
        input:focus + .slider {
            box-shadow: 0 0 1px var(--button-bg);
        }
        input:checked + .slider:before {
            transform: translateX(22px); /* Adjusted translation */
        }

        /* Responsive Adjustments */
        @media (max-width: 600px) {
            .app-container {
                height: 100vh; /* Full height on mobile */
                max-height: none;
                border-radius: 0;
                box-shadow: none;
            }
            header { padding: 0.75rem 1rem; }
            header h1 { font-size: 1.1rem; }
            main { padding: 0 1rem 0.75rem; }
            .input-area { margin-bottom: 0.5rem; } /* Space below input on mobile */
            .controls { gap: 0.5rem; margin-top: 0.5rem; /* Reduce space above controls */}
            .control-button { padding: 0.6rem 1rem; font-size: 0.85rem; }
            #configMenu { width: 85%; }
            .message { max-width: 90%; }
        }
    </style>
</head>
<body>
    <div class="app-container">
        <header>
            <h1><i class="fas fa-robot"></i> Chat con Gemini 2.0 Flash</h1>
            <div class="header-controls">
                <div id="contextIndicator" class="context-indicator empty" title="Cantidad de mensajes en memoria">
                    Contexto: 0 mensajes
                </div>
                <button id="toggleConfig" class="icon-button" title="Configuración">
                    <i class="fas fa-cog"></i>
                </button>
            </div>
        </header>

        <main>
            <div id="chat-container">
                <div id="chat"></div>
                <div id="typing-indicator" class="hidden">
                    <div class="dot"></div>
                    <div class="dot"></div>
                    <div class="dot"></div>
                </div>
            </div>

            <!-- El div #transcription-info ha sido eliminado -->

            <div class="input-area">
                <input type="text" id="input" placeholder="Escribe o usa comandos de voz..." />
                <button id="sendBtn" class="icon-button" title="Enviar mensaje">
                    <i class="fas fa-paper-plane"></i>
                </button>
            </div>

            <div class="controls">
                <button id="startBtn" class="control-button">
                    <i class="fas fa-microphone"></i> Hablar con Gemini
                </button>
                <button id="explicitStopBtn" class="control-button" disabled>
                     <i class="fas fa-microphone-slash"></i> Detener Escucha
                </button>
                <button id="pauseBtn" class="control-button" disabled>
                    <i class="fas fa-pause"></i> Pausar Lectura
                </button>
                <button id="resumeBtn" class="control-button" disabled>
                    <i class="fas fa-play"></i> Reanudar Lectura
                </button>
                <button id="stopBtn" class="control-button" disabled>
                    <i class="fas fa-stop"></i> Detener Lectura
                </button>
            </div>
        </main>

        <aside id="configMenu" class="hidden">
            <div class="config-header">
                <h3>Configuración</h3>
                <button id="closeConfig" class="icon-button">
                    <i class="fas fa-times"></i>
                </button>
            </div>

            <div class="config-section">
                <h4>Voz</h4>
                <label for="voiceSelect">Seleccionar Voz:</label>
                <select id="voiceSelect"></select>
            </div>

            <div class="config-section">
                <h4>Velocidad Lectura</h4>
                <div class="slider-container">
                    <i class="fas fa-walking"></i>
                    <input type="range" id="rateSelect" min="0.1" max="2" step="0.1" value="1">
                    <i class="fas fa-running"></i>
                </div>
                <span id="rateValue">1.0</span>
            </div>

            <div class="config-section">
                <h4>Tono Lectura</h4>
                <div class="slider-container">
                    <i class="fas fa-arrow-down"></i>
                    <input type="range" id="pitchSelect" min="0" max="2" step="0.1" value="1">
                    <i class="fas fa-arrow-up"></i>
                </div>
                <span id="pitchValue">1.0</span>
            </div>

            <div class="config-section">
                <h4>Contexto</h4>
                <button id="clearContextBtn" class="full-width-btn">
                    <i class="fas fa-trash"></i> Borrar contexto
                </button>
                <p class="help-text">Esto eliminará la memoria de la conversación actual.</p>
            </div>

            <div class="config-section">
                <h4>Tema</h4>
                <div class="theme-toggle">
                    <span>Claro</span>
                    <label class="switch">
                        <input type="checkbox" id="themeToggle">
                        <span class="slider round"></span>
                    </label>
                    <span>Oscuro</span>
                </div>
            </div>
        </aside>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/howler/2.2.3/howler.min.js"></script>
    <script>
    // --- Variables Globales ---
    // ⚠️ ADVERTENCIA DE SEGURIDAD: ¡NO EXPONGAS TU CLAVE API DIRECTAMENTE EN EL CÓDIGO DEL CLIENTE!
    // Considera usar un backend proxy o variables de entorno para protegerla.
    // Reemplaza "TU_API_KEY_AQUI" con tu clave real solo para pruebas locales y bajo tu responsabilidad.
    const API_KEY = "TU_API_KEY_AQUI"; // <-- ¡REEMPLAZA Y PROTEGE ESTO!

    let currentSpeech = null; // Almacena el objeto SpeechSynthesisUtterance actual
    let isRecording = false; // Intención del usuario de grabar (controlada por botones)
    let isApiRecognizing = false; // Estado real de la API SpeechRecognition
    let isSpeaking = false; // ¿Está activo el TTS actualmente?
    let voices = []; // Array para almacenar las voces TTS disponibles
    let isWaitingForResponse = false; // ¿Está la app esperando respuesta de la API Gemini?
    let wasRecordingBeforeTTS = false; // Bandera para recordar si el reconocimiento estaba activo antes del TTS
    let autoScrollEnabled = true; // Control para el auto-scroll

    // Variables for special voice commands
    let isListeningButNotTranscribing = false; // Estado para el comando "espera"
    let finalTranscript = ''; // Acumula los segmentos definitivos de la transcripción

    // Conversation history (context)
    let conversationHistory = [];
    const MAX_CONTEXT_LENGTH = 10; // Máx mensajes en contexto (ajustar según necesidad)

    // --- DOM Elements ---
    const chatElement = document.getElementById('chat');
    const chatContainer = document.getElementById('chat-container');
    const inputField = document.getElementById('input');
    const startBtn = document.getElementById('startBtn');
    const explicitStopBtn = document.getElementById('explicitStopBtn');
    const pauseBtn = document.getElementById('pauseBtn');
    const resumeBtn = document.getElementById('resumeBtn');
    const stopBtn = document.getElementById('stopBtn');
    const sendBtn = document.getElementById('sendBtn');
    const voiceSelect = document.getElementById('voiceSelect');
    const rateSelect = document.getElementById('rateSelect');
    const pitchSelect = document.getElementById('pitchSelect');
    const rateValue = document.getElementById('rateValue');
    const pitchValue = document.getElementById('pitchValue');
    const toggleConfigBtn = document.getElementById('toggleConfig');
    const configMenu = document.getElementById('configMenu');
    const closeConfigBtn = document.getElementById('closeConfig');
    const themeToggle = document.getElementById('themeToggle');
    const typingIndicator = document.getElementById('typing-indicator');
    const clearContextBtn = document.getElementById('clearContextBtn');
    const contextIndicator = document.getElementById('contextIndicator');
    // La variable transcriptionInfo ha sido eliminada

    // --- Sound Effects ---
    const sounds = {
        send: new Howl({ src: ['https://assets.mixkit.co/active_storage/sfx/2354/2354-preview.mp3'], volume: 0.4 }),
        receive: new Howl({ src: ['https://assets.mixkit.co/active_storage/sfx/2358/2358-preview.mp3'], volume: 0.4 }),
        start: new Howl({ src: ['https://assets.mixkit.co/active_storage/sfx/2570/2570-preview.mp3'], volume: 0.4 }),
        stop: new Howl({ src: ['https://assets.mixkit.co/active_storage/sfx/2571/2571-preview.mp3'], volume: 0.4 })
    };

    // --- Speech Recognition Setup ---
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    let recognition; // Declarar variable recognition

    if (!SpeechRecognition) {
        console.error("Speech Recognition API no soportada en este navegador.");
        alert("Lo siento, tu navegador no soporta el reconocimiento de voz.");
        if(startBtn) startBtn.disabled = true;
        if(explicitStopBtn) explicitStopBtn.disabled = true;
    } else {
        recognition = new SpeechRecognition();
        recognition.lang = 'es-ES'; // Asegurar idioma español
        recognition.interimResults = true;
        recognition.continuous = true; // Esencial para escucha continua
        recognition.maxAlternatives = 1;

        // --- Speech Recognition Event Handlers ---
        recognition.onstart = () => {
            isApiRecognizing = true; // Marcar que la API está escuchando activamente
            console.log("Recognition started.");
            updateButtonStates(); // Reflejar estado de escucha
            // Ya no se muestra mensaje de estado de transcripción
        };

        recognition.onresult = (event) => {
            // *** IMPORTANTE: Ignorar resultados si el TTS está hablando ***
            if (isSpeaking) {
                console.log("Ignoring recognition result: TTS is active.");
                return;
            }

            let interimTranscript = '';
            for (let i = event.resultIndex; i < event.results.length; ++i) {
                const transcriptPart = event.results[i][0].transcript;

                if (event.results[i].isFinal) {
                    console.log("Final segment:", transcriptPart);
                    const finalSegmentLower = transcriptPart.toLowerCase().trim();

                    if (!isListeningButNotTranscribing) {
                        // Comprobación de comandos ("okay", "espera")
                        if (finalSegmentLower.endsWith("okay") || finalSegmentLower.endsWith("okey")) {
                            const commandWord = finalSegmentLower.endsWith("okay") ? "okay" : "okey";
                            // Añadir la parte del transcript ANTES del comando "okay"
                            finalTranscript += transcriptPart.substring(0, transcriptPart.toLowerCase().lastIndexOf(commandWord)).trim();
                             // Quitar espacios extra al final si los hubiera
                            finalTranscript = finalTranscript.trim();
                            inputField.value = finalTranscript; // Actualizar input con texto final antes de enviar
                            console.log(`"Okay" detected. Sending: "${finalTranscript}"`);
                            if (finalTranscript) { // Enviar solo si hay texto
                                sendMessage(finalTranscript);
                            }
                            finalTranscript = ''; // Limpiar buffer
                            inputField.value = ''; // Limpiar campo de entrada
                            isListeningButNotTranscribing = false; // Asegurarse de que no está en espera
                            // No es necesario return aquí, el flujo continuará y limpiará
                        } else if (finalSegmentLower.includes("espera")) {
                            // Añadir la parte del transcript ANTES del comando "espera"
                            finalTranscript += transcriptPart.substring(0, transcriptPart.toLowerCase().lastIndexOf("espera")).trim();
                            finalTranscript = finalTranscript.trim(); // Limpiar espacios
                            inputField.value = finalTranscript + " [en espera...]"; // Mostrar estado en input
                            isListeningButNotTranscribing = true;
                            console.log(`"Espera" detected. Pausing transcription. Current: "${finalTranscript}"`);
                            updateButtonStates();
                        } else {
                            // Añadir segmento final normal
                            finalTranscript += transcriptPart + ' '; // Añadir espacio para separar frases
                            console.log("Appending final segment. Current:", finalTranscript);
                            // No mostrar estado de transcripción
                        }
                    } else { // En modo "espera"
                        if (finalSegmentLower.includes("continuemos")) {
                            isListeningButNotTranscribing = false;
                            inputField.value = finalTranscript.trim(); // Mostrar transcripción acumulada sin "[en espera...]"
                            console.log(`"Continuemos" detected. Resuming transcription. Current: "${finalTranscript.trim()}"`);
                            updateButtonStates();
                        } else {
                            console.log("Ignoring speech while in 'espera' mode:", transcriptPart);
                            // No mostrar estado de transcripción
                        }
                    }
                } else { // Resultados interinos
                    if (!isListeningButNotTranscribing) {
                        interimTranscript += transcriptPart;
                        // No se llama a updateTranscriptionInfo
                    }
                }
            }
            // Actualizar campo de entrada solo si no está en modo "espera"
            if (!isListeningButNotTranscribing) {
                 // Mostrar transcripción final + interina actual
                 // Trim() al final para evitar espacios colgantes si el intermedio está vacío
                inputField.value = (finalTranscript + interimTranscript).trim();
                ensureInputFieldVisible();
            }
        };

        recognition.onend = () => {
            isApiRecognizing = false; // Marcar que la API se ha detenido
            console.log("Recognition ended. isRecording(intent):", isRecording, "isWaiting:", isWaitingForResponse, "isSpeaking:", isSpeaking);
            // Ya no se oculta el estado de transcripción

            // No reiniciar si el TTS está hablando (el onend del TTS lo manejará)
            if (isSpeaking) {
                console.log("Recognition ended during TTS, waiting for TTS to finish.");
                updateButtonStates(); // Actualizar estado del botón aunque no se reinicie
                return;
            }
            // No reiniciar si se está esperando respuesta de la API
            if (isWaitingForResponse) {
                 console.log("Recognition ended while waiting for API response.");
                 updateButtonStates();
                 return;
            }
            // Solo reiniciar si el usuario *tiene la intención* de estar grabando
            if (isRecording) {
                console.log("Attempting restart (continuous mode, not speaking/waiting)...");
                // No mostrar estado de reconexión
                try {
                    // Usar un pequeño retraso para prevenir posibles problemas de reinicio rápido
                    setTimeout(() => {
                        // Doble comprobación del estado antes de iniciar realmente
                        if (isRecording && !isSpeaking && !isWaitingForResponse && !isApiRecognizing) {
                            console.log("Executing delayed restart.");
                            recognition.start();
                            // No mostrar estado "Escuchando..."
                        } else {
                             console.log("Restart aborted, state changed during delay.");
                             // Si el estado cambió de tal forma que no deberíamos grabar, actualizar botones
                             if (!isRecording) updateButtonStates();
                        }
                    }, 100); // Retraso corto
                } catch (e) {
                    console.error("Error restarting recognition:", e);
                    isRecording = false; // Falló el reinicio de la intención
                    updateButtonStates();
                    appendMessage('Error al reiniciar el reconocimiento de voz.', 'system-message', true);
                    // No ocultar estado de transcripción
                }
            } else {
                // El reconocimiento terminó y la intención del usuario NO es grabar (parada manual, error)
                updateButtonStates(); // Asegurar que los botones reflejen el estado detenido
                console.log("Recognition stopped definitively.");
                // No ocultar estado de transcripción
            }
        };

        recognition.onerror = (event) => {
            isApiRecognizing = false; // La API se detuvo por error
            console.error('Error en reconocimiento de voz:', event.error, event.message);

            let wasIntentRecording = isRecording; // Guardar intención antes de cambiarla potencialmente
            isRecording = false; // Generalmente detener la intención en error, excepto quizás 'no-speech'
            isListeningButNotTranscribing = false;
            finalTranscript = ''; // Limpiar buffer en error

            let errorMessage = `Error de reconocimiento: ${event.error}.`;
            if (event.message) errorMessage += ` ${event.message}`;

            if (event.error === 'not-allowed' || event.error === 'service-not-allowed') {
                errorMessage = 'Acceso al micrófono denegado. Por favor, habilita el permiso en tu navegador.';
            } else if (event.error === 'no-speech') {
                errorMessage = 'No se detectó voz. Intenta de nuevo.';
                 // Para 'no-speech', podemos dejar que 'onend' intente reiniciar si la intención era grabar
                isRecording = wasIntentRecording; // Restaurar intención, dejar que onend maneje reinicio si es necesario
            } else if (event.error === 'network') {
                 errorMessage = 'Error de red durante el reconocimiento de voz.';
            } else if (event.error === 'audio-capture') {
                 errorMessage = 'Error al capturar audio del micrófono.';
            }

            appendMessage(errorMessage, 'system-message', true);
            updateButtonStates(); // Actualizar botones después de manejar error
            // No mostrar estado de error de transcripción

             // Si el error es crítico, asegurar que el reconocimiento no se reinicie vía onend
            if (event.error === 'not-allowed' || event.error === 'service-not-allowed' || event.error === 'audio-capture') {
                 isRecording = false; // Forzar la detención de la intención
            }

            // Si el error fue 'no-speech' y la intención era grabar, onend debería intentar reiniciar
            if (event.error === 'no-speech' && isRecording) {
                 console.log("No-speech error occurred, letting onend handle potential restart.");
            } else {
                 // Para otros errores, nos aseguramos de que la intención de grabar se detenga
                 isRecording = false;
                 updateButtonStates();
            }
        };
    }

    // --- Funciones para estado de transcripción ELIMINADAS ---
    // function showTranscriptionStatus(message) { ... }
    // function hideTranscriptionStatus() { ... }
    // function updateTranscriptionInfo(interimText) { ... }

    // --- Initialization Functions ---
    function loadSavedTheme() {
        const savedTheme = localStorage.getItem('theme') || 'light';
        document.body.setAttribute('data-theme', savedTheme);
        if(themeToggle) themeToggle.checked = savedTheme === 'dark';
    }

    function loadSavedConfig() {
        loadSavedTheme();
        const savedRate = localStorage.getItem('rate') || 1;
        const savedPitch = localStorage.getItem('pitch') || 1;
        if(rateSelect) rateSelect.value = savedRate;
        if(pitchSelect) pitchSelect.value = savedPitch;
        if(rateValue) rateValue.textContent = parseFloat(savedRate).toFixed(1);
        if(pitchValue) pitchValue.textContent = parseFloat(savedPitch).toFixed(1);

        const savedHistory = localStorage.getItem('conversationHistory');
        if (savedHistory) {
            try {
                conversationHistory = JSON.parse(savedHistory);
                restoreConversationHistory();
            } catch (e) {
                console.error("Error al cargar historial:", e);
                conversationHistory = [];
                localStorage.removeItem('conversationHistory');
            }
        }
        updateContextIndicator();
    }

    function restoreConversationHistory() {
        if (!chatElement) return;
        chatElement.innerHTML = '';
        conversationHistory.forEach(message => {
            // Usa 'model' para el bot en la API, pero 'bot-message' para la clase CSS
            const className = message.role === 'user' ? 'user-message' : 'bot-message';
            appendMessageToUI(message.text, className, true); // skipHistory = true para no volver a guardar
        });
        scrollToBottom();
    }

    function loadVoices() {
        // Intenta obtener las voces inmediatamente, puede que ya estén cargadas
        voices = speechSynthesis.getVoices();
        if (voices.length === 0) {
            // Si no están cargadas, espera al evento onvoiceschanged
             speechSynthesis.onvoiceschanged = () => {
                voices = speechSynthesis.getVoices();
                populateVoiceList();
            };
        } else {
             // Si ya estaban cargadas, puebla la lista
             populateVoiceList();
        }
    }

    function populateVoiceList() {
         if (!voiceSelect) return;
        voiceSelect.innerHTML = ''; // Limpiar opciones existentes

        const spanishVoices = voices.filter(voice => voice.lang.startsWith('es'));
        const otherVoices = voices.filter(voice => !voice.lang.startsWith('es'));

        // Añadir un separador si hay voces en español y otros idiomas
        let addedSeparator = false;

        spanishVoices.forEach((voice, index) => {
            const option = document.createElement('option');
            // Usa el índice original en el array 'voices' como valor
            option.value = voices.indexOf(voice);
            option.textContent = `${voice.name} (${voice.lang})`;
            voiceSelect.appendChild(option);
        });

        if (spanishVoices.length > 0 && otherVoices.length > 0) {
             const separator = document.createElement('option');
             separator.disabled = true;
             separator.textContent = '--- Otras Voces ---';
             voiceSelect.appendChild(separator);
             addedSeparator = true;
        }

        otherVoices.forEach((voice, index) => {
             const option = document.createElement('option');
             option.value = voices.indexOf(voice); // Usa el índice original
             option.textContent = `${voice.name} (${voice.lang})`;
             voiceSelect.appendChild(option);
        });

        // Seleccionar voz guardada o la primera en español como predeterminada
        const savedVoiceIndex = localStorage.getItem('selectedVoice');
        let defaultSpanishIndex = -1;
        if(spanishVoices.length > 0) {
            defaultSpanishIndex = voices.indexOf(spanishVoices[0]);
        }

        if (savedVoiceIndex && voices[parseInt(savedVoiceIndex)]) {
            voiceSelect.value = savedVoiceIndex;
        } else if (defaultSpanishIndex !== -1) {
             voiceSelect.value = defaultSpanishIndex; // Seleccionar primera española por defecto
             localStorage.setItem('selectedVoice', defaultSpanishIndex);
        } else if (voiceSelect.options.length > 0) {
             voiceSelect.selectedIndex = 0; // Fallback a la primera opción si no hay española
             localStorage.setItem('selectedVoice', voiceSelect.value);
        }

        // Carga otras configuraciones después de que las voces estén listas
        loadSavedConfig();
    }

    loadVoices(); // Llamada inicial para cargar voces

    // --- UI Update Functions ---

    // Función para agregar mensaje al DOM
    function appendMessageToUI(message, className, skipHistory = false) {
        if (!chatElement) return;
        const messageDiv = document.createElement('div');
        // Sanitizar HTML básico para evitar inyección simple
        const sanitizedMessage = message.replace(/</g, "<").replace(/>/g, ">");
        // Reemplazar saltos de línea con <br> para visualización correcta
        messageDiv.innerHTML = sanitizedMessage.replace(/\n/g, '<br>');
        messageDiv.className = `message ${className}`;

        // Añadir botón de altavoz solo a mensajes del bot
        if (className === 'bot-message') {
            const speakButton = document.createElement('button');
            speakButton.className = 'speak-button';
            speakButton.innerHTML = '<i class="fas fa-volume-up"></i>';
            speakButton.title = 'Reproducir este mensaje';
            speakButton.addEventListener('click', (e) => {
                 e.stopPropagation(); // Evitar que otros listeners se activen
                 readSpecificMessage(message);
            });
            messageDiv.appendChild(speakButton);
        }

        chatElement.appendChild(messageDiv);
        // Solo hacer scroll si el autoscroll está habilitado
        if(autoScrollEnabled) {
            scrollToBottom();
        }
    }

    // Hacer scroll al último mensaje
    function scrollToBottom() {
        if (chatContainer) {
            // Usar requestAnimationFrame para asegurar que el DOM se ha actualizado
            requestAnimationFrame(() => {
                chatContainer.scrollTop = chatContainer.scrollHeight;
            });
        }
    }

     // Asegurarse de que el campo de entrada esté visible (hace scroll al fondo)
    function ensureInputFieldVisible() {
        scrollToBottom();
    }


    function appendMessage(message, className, isSystemMessage = false) {
        // Añadir mensaje a la UI
        appendMessageToUI(message, className, isSystemMessage);

        // Guardar en el historial y localStorage si no es un mensaje del sistema
        if (!isSystemMessage) {
            const role = className === 'user-message' ? 'user' : 'model';
            // Guardar el texto original (sin sanitizar) en el historial
            conversationHistory.push({ role, text: message });
            // Limitar tamaño del historial
            if (conversationHistory.length > MAX_CONTEXT_LENGTH) {
                conversationHistory = conversationHistory.slice(-MAX_CONTEXT_LENGTH);
            }
            // Guardar en localStorage
            try {
                 localStorage.setItem('conversationHistory', JSON.stringify(conversationHistory));
            } catch (e) {
                 console.error("Error guardando historial en localStorage:", e);
                 // Opcional: Informar al usuario o intentar limpiar localStorage
            }
            updateContextIndicator(); // Actualizar indicador de contexto
        }

        // Reproducir sonidos y hablar si es un mensaje del bot
        if (!isSystemMessage) {
            if (className === 'user-message') {
                sounds.send.play();
            } else if (className === 'bot-message') {
                sounds.receive.play();
                readAloud(message); // Disparar TTS para mensajes del bot
            }
        }
    }

    // Nueva función para leer un mensaje específico al hacer clic en el botón
    function readSpecificMessage(message) {
         console.log("Attempting to read specific message.");
        if (isSpeaking) {
            console.log("Stopping current speech before reading specific message.");
            window.speechSynthesis.cancel(); // Detener la locución actual si existe
            // El estado se actualizará en el onend/onerror de la locución cancelada
        }

        // Pequeño retraso para asegurar que la cancelación se procese
        setTimeout(() => {
            readAloud(message, true); // true indica que es una lectura específica
        }, 50); // 50ms puede ser suficiente
    }


    function updateContextIndicator() {
        if (contextIndicator) {
            const count = conversationHistory.length;
            contextIndicator.textContent = `Contexto: ${count} mensajes`;
            contextIndicator.classList.remove('empty', 'medium', 'full');
            if (count === 0) contextIndicator.classList.add('empty');
            else if (count < MAX_CONTEXT_LENGTH / 2) contextIndicator.classList.add('medium');
            else contextIndicator.classList.add('full');
            contextIndicator.title = `La conversación recordará los últimos ${count} mensajes (máx ${MAX_CONTEXT_LENGTH})`;
        }
    }

    function clearContext() {
        conversationHistory = [];
        localStorage.removeItem('conversationHistory');
        updateContextIndicator();
        appendMessage('Contexto borrado. La conversación empieza de nuevo.', 'system-message', true);
    }

    function showTypingIndicator() { if(typingIndicator) typingIndicator.classList.remove('hidden'); scrollToBottom(); }
    function hideTypingIndicator() { if(typingIndicator) typingIndicator.classList.add('hidden'); }

    function updateButtonStates() {
        const recognitionActuallyRunning = isApiRecognizing; // Estado real de la API
        const userWantsToRecord = isRecording; // Intención del usuario
        const ttsSpeaking = isSpeaking;
        const ttsPaused = currentSpeech && window.speechSynthesis.paused;

        // Botón Iniciar/Hablar
        if (startBtn) {
             // Deshabilitar si la API está escuchando, o esperando respuesta, o TTS está activo
            startBtn.disabled = recognitionActuallyRunning || isWaitingForResponse || ttsSpeaking;
            if (recognitionActuallyRunning) {
                 if (isListeningButNotTranscribing) {
                    startBtn.innerHTML = '<i class="fas fa-spinner fa-spin"></i> En espera...';
                 } else {
                    startBtn.innerHTML = '<i class="fas fa-microphone-alt"></i> Escuchando...';
                 }
            } else {
                 startBtn.innerHTML = '<i class="fas fa-microphone"></i> Hablar con Gemini';
            }
        }

        // Botón Detener Escucha Explícito
        if (explicitStopBtn) {
            // Habilitar si la API está escuchando O si el usuario tiene la intención de grabar (incluso si la API se detuvo temporalmente, ej. por TTS)
            explicitStopBtn.disabled = !recognitionActuallyRunning && !userWantsToRecord;
        }

        // Botones de control de TTS
        if (pauseBtn) pauseBtn.disabled = !ttsSpeaking || ttsPaused;
        if (resumeBtn) resumeBtn.disabled = !ttsPaused;
        if (stopBtn) stopBtn.disabled = !ttsSpeaking && !ttsPaused; // Se puede detener si está hablando o pausado
    }

    // --- Core Logic Functions ---
    function sendMessage(userInput) {
        const trimmedInput = userInput.trim();
        if (!trimmedInput) return;
        if(inputField) inputField.value = ''; // Limpiar input al enviar

        appendMessage(trimmedInput, 'user-message'); // Muestra el mensaje del usuario

        // Comandos locales (ejemplos)
        if (trimmedInput.toLowerCase().match(/^(qué hora es|dime la hora|hora actual|tiempo)$/)) {
            try { appendMessage(`La hora actual es: ${obtenerHora()}`, 'bot-message'); return; }
            catch (error) { console.error("Error obteniendo hora:", error); }
        }
        if (trimmedInput.toLowerCase().match(/^(borrar contexto|olvida todo|nueva conversación|empezar de nuevo)$/)) {
            clearContext(); return;
        }

        // Preparar y enviar a la API de Gemini
        showTypingIndicator();
        isWaitingForResponse = true; // Marcar que estamos esperando respuesta
        updateButtonStates(); // Actualizar botones

        // Detener reconocimiento si está activo ANTES de enviar a la API
        // Esto evita que siga transcribiendo mientras espera la respuesta.
        if (isApiRecognizing) {
            console.log("Stopping recognition while waiting for API response.");
            try {
                recognition.stop();
            } catch(e) { console.error("Error stopping recognition before API call:", e); }
        }

        const messages = prepareMessagesWithContext(); // Prepara historial + mensaje nuevo

        // Validar API_KEY antes de la llamada
        if (API_KEY === "TU_API_KEY_AQUI" || !API_KEY) {
             console.error("API Key no configurada!");
             appendMessage("Error: La clave API no está configurada. Por favor, configúrala en el código.", 'system-message', true);
             hideTypingIndicator();
             isWaitingForResponse = false;
             updateButtonStates();
             // Considerar reiniciar reconocimiento si estaba activo antes
             checkAndRestartRecognition();
             return; // Detener ejecución si no hay clave
        }


        fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=${API_KEY}`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ contents: messages })
        })
        .then(response => {
            if (!response.ok) {
                // Intentar leer el cuerpo del error para más detalles
                return response.json().then(errData => {
                     // Construir un mensaje de error más informativo
                    let errMsg = `Error ${response.status}: ${response.statusText}.`;
                    if (errData && errData.error && errData.error.message) {
                        errMsg += ` Detalles: ${errData.error.message}`;
                    }
                    // Rechazar la promesa con el mensaje de error construido
                    return Promise.reject(new Error(errMsg));
                });
            }
            return response.json(); // Continuar si la respuesta es OK
        })
        .then(data => {
            // Extraer la respuesta del bot de forma segura
            const respuesta = data?.candidates?.[0]?.content?.parts?.[0]?.text || 'Lo siento, no pude procesar esa respuesta.';
            appendMessage(respuesta, 'bot-message');
        })
        .catch(error => {
            console.error("Error en la llamada API o procesando respuesta:", error);
            // Mostrar mensaje de error más genérico o el específico si está disponible
            const errorMsg = error.message || 'Ocurrió un error al contactar con Gemini.';
            appendMessage(`Error API: ${errorMsg}`, 'system-message', true);
        })
        .finally(() => {
            hideTypingIndicator();
            isWaitingForResponse = false; // Ya no estamos esperando
            finalTranscript = ''; // Limpiar buffer de transcripción después del intento de envío
            updateButtonStates(); // Actualizar estado de botones
            // Importante: Verificar si se debe reiniciar el reconocimiento
            checkAndRestartRecognition();
        });
    }

     // Función para verificar y reiniciar el reconocimiento después de una acción (API, TTS)
    function checkAndRestartRecognition() {
        // Solo reiniciar si la intención del usuario es grabar Y la API no está ya reconociendo Y no está hablando
        if (isRecording && !isApiRecognizing && !isSpeaking) {
            console.log("Checking and potentially restarting recognition after action.");
            try {
                // Usar un pequeño delay para asegurar que otros procesos (como TTS onend) finalicen
                setTimeout(() => {
                     if (isRecording && !isApiRecognizing && !isSpeaking) {
                         console.log("Executing delayed recognition restart.");
                         recognition.start();
                     } else {
                         console.log("Recognition restart aborted, state changed during delay.");
                     }
                }, 150); // Un poco más de delay
            } catch(e) {
                console.error("Error trying to restart recognition:", e);
                isRecording = false; // Si falla, actualizar intención y botones
                updateButtonStates();
            }
        } else {
             console.log("No need to restart recognition. State:", {isRecording, isApiRecognizing, isSpeaking});
             // Asegurarse de que los botones estén actualizados incluso si no se reinicia
             updateButtonStates();
        }
    }

    // Prepara el historial de conversación para la API
    function prepareMessagesWithContext() {
         // Puedes añadir un prompt de sistema aquí si lo necesitas
        const systemPrompt = {
             role: "user", // Gemini prefiere que los prompts de sistema sean 'user'
             parts: [{ text: "Eres un asistente IA conversacional llamado Gemini 2.0 Flash. Responde siempre en español de España, de forma amable, concisa y útil. Evita formalismos excesivos." }]
        };
         const systemResponse = {
             role: "model",
             parts: [{ text: "¡Entendido! Soy Gemini 2.0 Flash, listo para ayudarte en español. ¿Qué necesitas?" }]
         };

        // Formatea el historial existente
        const formattedHistory = conversationHistory.map(msg => ({
            role: msg.role, // 'user' o 'model'
            parts: [{ text: msg.text }]
        }));

        // Combina el prompt, la respuesta de ejemplo y el historial
        // Asegúrate de que el último mensaje sea del usuario si es posible
        return [systemPrompt, systemResponse, ...formattedHistory];
    }

    // --- Text-to-Speech (TTS) Functions ---
    function readAloud(text, isSpecificMessage = false) {
        if (!('speechSynthesis' in window)) {
            console.error('TTS no soportado en este navegador.');
            return;
        }
        if (!text || typeof text !== 'string' || text.trim() === '') {
             console.warn('Intento de leer texto vacío o inválido.');
             return;
        }

        // Cancelar cualquier locución anterior ANTES de configurar la nueva
        // Esto es importante para evitar solapamientos y asegurar que onend/onerror se llamen correctamente
        window.speechSynthesis.cancel();

        // Solo detener el reconocimiento si NO es una lectura específica de mensaje
        if (!isSpecificMessage && recognition) {
             // Guardar la intención del usuario ANTES de detener
            wasRecordingBeforeTTS = isRecording;
            if (isApiRecognizing) { // Detener solo si la API está realmente activa
                try {
                    console.log("Temporarily stopping recognition for general TTS.");
                    recognition.stop(); // Detener escucha de la API
                    // isApiRecognizing se pondrá a false en el evento onend de recognition
                } catch(e) {
                     console.error("Error stopping recognition for TTS:", e);
                     // Intentar continuar con TTS de todas formas
                }
            } else {
                 console.log("Recognition API not running, no need to stop for TTS.");
            }
        } else if (isSpecificMessage) {
            // Si es una lectura específica, nos aseguramos de no reiniciar el reconocimiento después
             wasRecordingBeforeTTS = false;
             console.log("Reading specific message, recognition state unchanged.");
        }

        currentSpeech = new SpeechSynthesisUtterance(text);
        const selectedVoiceIndex = voiceSelect ? parseInt(voiceSelect.value) : -1;

        // Asegurarse de que el índice es válido y existe en el array `voices`
        if (selectedVoiceIndex !== -1 && voices[selectedVoiceIndex]) {
            currentSpeech.voice = voices[selectedVoiceIndex];
        } else {
             // Fallback: buscar la primera voz en español disponible si la selección falló
             const firstSpanishVoice = voices.find(v => v.lang.startsWith('es'));
             if (firstSpanishVoice) {
                 currentSpeech.voice = firstSpanishVoice;
                 console.warn("Voz seleccionada no encontrada, usando primera voz en español.");
             } else if (voices.length > 0) {
                 currentSpeech.voice = voices[0]; // Fallback a la primera voz disponible
                 console.warn("Voz seleccionada no encontrada y no hay voces en español, usando la primera voz disponible.");
            } else {
                 console.error("No hay voces disponibles para TTS.");
                 // Quizás actualizar UI para indicar error de voz
                 return; // No se puede hablar si no hay voces
            }
        }

        if(rateSelect) currentSpeech.rate = parseFloat(rateSelect.value);
        if(pitchSelect) currentSpeech.pitch = parseFloat(pitchSelect.value);
        currentSpeech.lang = currentSpeech.voice?.lang || 'es-ES'; // Asegurar que el lang coincida con la voz

        currentSpeech.onstart = () => {
            console.log("TTS started");
            isSpeaking = true;
            updateButtonStates(); // Actualizar botones al iniciar TTS
        };

        const handleSpeechEnd = (errorOccurred = false) => {
            const status = errorOccurred ? "error" : "finished";
            console.log(`TTS ${status}. isSpecificMessage: ${isSpecificMessage}, wasRecordingBeforeTTS: ${wasRecordingBeforeTTS}`);

            // Restablecer estado independientemente del tipo de finalización
            isSpeaking = false;
            currentSpeech = null; // Liberar la referencia

             // Verificar si se debe reiniciar el reconocimiento
             // Solo reiniciar si:
             // 1. NO era una lectura específica.
             // 2. La intención del usuario ANTES de empezar TTS era grabar.
             // 3. La API de reconocimiento no está ya activa (por si acaso).
            if (!isSpecificMessage && wasRecordingBeforeTTS && recognition && !isApiRecognizing) {
                 console.log("Attempting to restart recognition after general TTS finished.");
                 checkAndRestartRecognition(); // Usar la función centralizada
            } else {
                 // Si no se reinicia, al menos actualizar los botones
                 updateButtonStates();
            }
            wasRecordingBeforeTTS = false; // Limpiar la bandera siempre al final
        };

        currentSpeech.onend = () => handleSpeechEnd(false);
        currentSpeech.onerror = (event) => {
            console.error('TTS Error:', event.error, event.utterance.text.substring(0, 50) + '...');
            appendMessage(`Error al reproducir voz: ${event.error}`, 'system-message', true);
            handleSpeechEnd(true); // Manejar como finalización (con error)
        };

        // Asegurarse de que la síntesis está lista antes de hablar
        if (window.speechSynthesis.pending === false) {
             window.speechSynthesis.speak(currentSpeech);
        } else {
             console.warn("Speech synthesis queue is busy, trying again shortly.");
             // Reintentar después de un breve retraso si la cola está ocupada
             setTimeout(() => {
                 if (!isSpeaking) { // Solo intentar si no empezó otra cosa mientras tanto
                     window.speechSynthesis.speak(currentSpeech);
                 }
             }, 100);
        }
    }


    function pauseReading() {
         if (isSpeaking && !window.speechSynthesis.paused) {
            window.speechSynthesis.pause();
            console.log("TTS paused.");
            updateButtonStates();
        }
    }
    function resumeReading() {
         if (window.speechSynthesis.paused) {
            window.speechSynthesis.resume();
            console.log("TTS resumed.");
            updateButtonStates();
         }
    }
    function stopReading() {
        if (isSpeaking || window.speechSynthesis.paused) {
             console.log("Stopping TTS explicitly.");
             window.speechSynthesis.cancel(); // Esto disparará onend/onerror que maneja el estado
             sounds.stop.play();
             // El estado (isSpeaking, currentSpeech) se restablece en handleSpeechEnd
             // wasRecordingBeforeTTS también se limpia ahí, evitando reinicio no deseado
        }
    }

    // --- Event Listeners ---
    if(startBtn && recognition) {
        startBtn.addEventListener('click', () => {
            // Solo iniciar si NO está esperando API, NO está ya reconociendo y NO está hablando
            if (!isWaitingForResponse && !isApiRecognizing && !isSpeaking) {
                finalTranscript = ""; // Limpiar buffer de transcripción
                if(inputField) inputField.value = ""; // Limpiar campo de texto
                isListeningButNotTranscribing = false; // Resetear modo espera
                isRecording = true; // Establecer la INTENCIÓN del usuario de grabar
                try {
                    recognition.start();
                    sounds.start.play();
                    console.log("Attempting to start recognition via button...");
                    // El estado de los botones se actualizará en recognition.onstart
                } catch(e) {
                    // Capturar errores síncronos al llamar a start() (ej. si ya está corriendo)
                    console.error("Error trying to start recognition:", e);
                    isRecording = false; // Revertir intención si start() falla inmediatamente
                    appendMessage('Error al iniciar reconocimiento. ¿Ya está activo?', 'system-message', true);
                    updateButtonStates(); // Actualizar botones para reflejar el fallo
                }
            } else {
                 console.log("Cannot start recognition. State:", {isWaitingForResponse, isApiRecognizing, isSpeaking});
                 // Opcional: dar feedback al usuario si el botón está deshabilitado
            }
        });
    }

    if(explicitStopBtn && recognition) {
        explicitStopBtn.addEventListener('click', () => {
            // Detener si la intención es grabar O si la API está activa
            if (isRecording || isApiRecognizing) {
                console.log("Explicitly stopping recognition via button.");
                isRecording = false; // Limpiar la INTENCIÓN del usuario
                wasRecordingBeforeTTS = false; // Asegurar que no se reinicie por TTS después
                isListeningButNotTranscribing = false; // Salir del modo espera si estaba activo

                if (isApiRecognizing) { // Solo llamar a stop() si la API está realmente activa
                    try {
                        recognition.stop(); // Detener la API
                    } catch(e) { console.error("Error stopping recognition:", e); }
                }
                sounds.stop.play();
                updateButtonStates(); // Actualizar UI inmediatamente
                // No ocultar estado de transcripción (ya no existe)
                if(inputField && inputField.value.endsWith("[en espera...]")) {
                    inputField.value = finalTranscript.trim(); // Limpiar el "[en espera...]" del input
                }
            }
        });
    }

    if(pauseBtn) pauseBtn.addEventListener('click', pauseReading);
    if(resumeBtn) resumeBtn.addEventListener('click', resumeReading);
    if(stopBtn) stopBtn.addEventListener('click', stopReading);

    if(sendBtn) sendBtn.addEventListener('click', () => { if(inputField) sendMessage(inputField.value); });
    if(inputField) {
        inputField.addEventListener('keypress', (e) => {
            // Enviar con Enter (si no se presiona Shift para nueva línea)
            if (e.key === 'Enter' && !e.shiftKey) {
                 e.preventDefault(); // Evitar nueva línea por defecto
                 sendMessage(inputField.value);
            }
        });
        // Limpiar "[en espera...]" si el usuario empieza a escribir manualmente
         inputField.addEventListener('input', () => {
             if (isListeningButNotTranscribing && inputField.value === finalTranscript + " [en espera...]") {
                 // Si el usuario borra el marcador de espera, salir del modo espera
                 if (!inputField.value.endsWith("[en espera...]")) {
                    isListeningButNotTranscribing = false;
                    finalTranscript = inputField.value; // Actualizar transcript con lo que quede
                    console.log("Exited 'espera' mode by manual input change.");
                    updateButtonStates();
                 }
             }
         });
    }


    // Config listeners
    if(rateSelect) rateSelect.addEventListener('input', () => { const r = rateSelect.value; localStorage.setItem('rate', r); if(rateValue) rateValue.textContent = parseFloat(r).toFixed(1); });
    if(pitchSelect) pitchSelect.addEventListener('input', () => { const p = pitchSelect.value; localStorage.setItem('pitch', p); if(pitchValue) pitchValue.textContent = parseFloat(p).toFixed(1); });
    if(voiceSelect) voiceSelect.addEventListener('change', () => { localStorage.setItem('selectedVoice', voiceSelect.value); }); // Guardar el value (índice)
    if(toggleConfigBtn) toggleConfigBtn.addEventListener('click', () => { if(configMenu) { configMenu.classList.toggle('hidden'); } });
    if(closeConfigBtn) closeConfigBtn.addEventListener('click', () => { if(configMenu) { configMenu.classList.add('hidden'); } });
    if(themeToggle) themeToggle.addEventListener('change', () => { const th = themeToggle.checked ? 'dark' : 'light'; document.body.setAttribute('data-theme', th); localStorage.setItem('theme', th); });
    if(clearContextBtn) clearContextBtn.addEventListener('click', clearContext);

    // Listener para manejo de scroll automático
    if (chatContainer) {
        let userScrolledUp = false;
        chatContainer.addEventListener('scroll', () => {
            // Calcula si el usuario está cerca del fondo
            const threshold = 50; // Píxeles desde el fondo para considerar "en el fondo"
            const isNearBottom = chatContainer.scrollHeight - chatContainer.scrollTop - chatContainer.clientHeight < threshold;

            if (isNearBottom) {
                 // Si el usuario vuelve al fondo, reactivar auto-scroll
                 if (userScrolledUp) {
                     console.log("User scrolled back to bottom, re-enabling auto-scroll.");
                     autoScrollEnabled = true;
                     userScrolledUp = false;
                 }
            } else {
                 // Si el usuario hace scroll hacia arriba (y no estaba ya arriba), desactivar auto-scroll
                 if (autoScrollEnabled) {
                     console.log("User scrolled up, disabling auto-scroll.");
                     autoScrollEnabled = false;
                     userScrolledUp = true;
                 }
            }
        }, { passive: true }); // Usar listener pasivo para mejor rendimiento de scroll
    }


    // --- Initial Setup ---
    window.addEventListener('DOMContentLoaded', () => {
        // loadVoices y loadSavedConfig ya se llaman/encadenan al inicio
        setTimeout(() => {
            if (conversationHistory.length === 0) {
                // Mensaje inicial mejorado explicando comandos clave
                appendMessage('¡Hola! Soy Gemini 2.0 Flash. Puedes escribir o hacer clic en "Hablar con Gemini". Para enviar tu mensaje por voz, termina diciendo "okay". Usa "espera" para pausar la transcripción y "continuemos" para reanudarla. Puedes reproducir mis respuestas con el botón <i class="fas fa-volume-up"></i> en mis mensajes.', 'bot-message');
            }
             updateButtonStates(); // Establecer estado inicial correcto de los botones
        }, 500); // Pequeño retraso para asegurar que todo esté listo
    });

    // --- Utility Functions ---
    function obtenerHora() {
        return new Date().toLocaleTimeString('es-ES', { hour: '2-digit', minute: '2-digit' });
    }

    // Limpieza al cerrar la pestaña/navegador (opcional, puede ser útil para detener reconocimiento)
    window.addEventListener('beforeunload', () => {
        if (recognition && isApiRecognizing) {
             recognition.abort(); // Usar abort para una detención más inmediata
             console.log("Recognition aborted due to page unload.");
        }
        if (window.speechSynthesis) {
             window.speechSynthesis.cancel(); // Cancelar TTS
        }
    });

    </script>
</body>
</html>
